# Issue #31: Library re-classification audit — validate existing films against current routing rules

**Severity:** High (blocks Issue #30 tentpole ranking and all Stage 3–5 curatorial work)
**Component:** new script `scripts/reaudit.py`, `classify.py` (reuse classification logic), `audit.py` (input data)
**Type:** Tooling — new read-only diagnostic script
**Discovered via:** Category pollution audit (2026-02-22)
**Depends on:** Nothing (can be built immediately)
**Blocks:** Issue #30 (tentpole ranking requires clean categories first)

---

## Summary

The classification pipeline (`classify.py`) only processes new films entering through the Unsorted queue. It writes `sorting_manifest.csv` and `move.py` executes the moves. But **~500 films already in the organized library were placed manually before the pipeline existed** or by earlier, looser routing rules. These films have never been re-evaluated against the current routing rules.

The result is severe category pollution. American Exploitation contains *Dead Poets Society*. European Sexploitation contains *Belle de Jour*. Blaxploitation contains *Miller's Crossing*. These are not borderline cases — they are plainly wrong, and there are dozens more like them.

No existing tool addresses this:
- `classify.py` only scans a source directory (the Unsorted folder)
- `audit.py` reads folder paths and reports inventory — it does not reclassify
- `move.py` reads the manifest — it cannot generate one from existing library contents

The system needs a re-classification audit: run each organized film through the current routing rules and flag discrepancies between "where the film IS" (folder) and "where it SHOULD BE" (classifier output).

---

## The Problem

### Evidence of pollution (from `library_audit.csv`, 2026-02-22)

**American Exploitation (97 films, cap 60) — contains at minimum:**
- Dead Poets Society (1989) — Robin Williams prestige drama
- Three Days of the Condor (1975) — Pollack/Redford political thriller
- Leaving Las Vegas (1995) — Mike Figgis Oscar film
- Paris Is Burning (1990) — landmark documentary
- High Art (1998) — indie drama
- True Stories (1986) — David Byrne art film
- Wait Until Dark (1967) — Audrey Hepburn thriller
- How to Steal a Million (1966) — William Wyler caper
- Bobby Deerfield (1977) — Pollack/Pacino drama
- Hombre (1967) — Martin Ritt/Paul Newman western
- Pleasantville (1998) — mainstream comedy
- Thelonious Monk: Straight No Chaser (1988) — music documentary

**European Sexploitation (24 films) — contains:**
- Belle de Jour (1967) — Buñuel (Core auteur candidate)
- A Man and a Woman (1966) — Lelouch (mainstream French cinema)
- The Cook, The Thief, His Wife & Her Lover (1989) — Greenaway (art cinema)
- Going Places (1974) — Blier (auteur comedy)
- La Grande Bouffe (1973) — Ferreri (art cinema provocation)
- Fedora (1978) — Billy Wilder (Classic Hollywood director)

**Blaxploitation (13 films) — contains:**
- Miller's Crossing (1990) — Coen brothers crime drama
- Nick of Time (1995) — Johnny Depp thriller
- Dirty Mary Crazy Larry (1974) — car chase film (no Blaxploitation connection)

### Root cause

These films were NOT misrouted by `classify.py`. They return `null` in both API caches and do not appear in `sorting_manifest.csv`. They were placed manually before the pipeline existed. The current routing rules would correctly reject all of them from these categories.

The architectural gap: **no mechanism exists to apply current routing rules retroactively to the existing library.** This was acknowledged in `docs/theory/REFINEMENT_AND_EMERGENCE.md` (previously §4 Component 3: "a future `--audit-existing` mode"), but never built.

### Why this blocks everything downstream

From the curatorial lifecycle (REFINEMENT_AND_EMERGENCE.md §4a):
- **Stage 3 (Refine)** — cannot happen without a re-audit tool
- **Stage 4 (Retain/Discard)** — cannot rank tentpoles in polluted categories (Issue #30)
- **Stage 5 (Reinforce)** — no confirmed curatorial decisions to feed back into the model
- **SATELLITE_DEPTH.md §5 (Vertical seeking)** — within-category vetting is distorted if the category contains films that don't belong

---

## What the tool does

A read-only diagnostic script that:
1. Reads `library_audit.csv` (current library inventory, generated by `audit.py`)
2. For each film, runs it through the current classification pipeline (API lookup + routing rules)
3. Compares the result to the film's current folder location
4. Outputs a discrepancy report

### Output: discrepancy report

```
scripts/reaudit.py → output/reaudit_report.csv
```

Columns:
```
filename, current_tier, current_category, current_decade,
classified_tier, classified_category, classified_decade,
match, discrepancy_type, confidence, notes
```

Where:
- `match` = `true` (film is where the classifier would put it) or `false` (discrepancy)
- `discrepancy_type`:
  - `wrong_category` — same tier, different category (e.g., AmEx → Popcorn)
  - `wrong_tier` — different tier entirely (e.g., Satellite → Core)
  - `no_data` — API returned nothing; cannot reclassify (needs manual review)
  - `unroutable` — classifier returns Unsorted (film doesn't match any current rule)
- `confidence`:
  - `high` — director match or explicit lookup drove the classification
  - `medium` — country + genre + decade structural match
  - `low` — keyword-only or single-signal match
  - `none` — no API data available

### Example output rows

```csv
"Dead Poets Society (1989).mkv", Satellite, American Exploitation, 1980s, ?, ?, ?, false, no_data, none, "No API data; manual review required"
"Belle de Jour (1967).mkv", Satellite, European Sexploitation, 1960s, Core, Luis Buñuel, 1960s, false, wrong_tier, high, "Buñuel in Core director whitelist"
"Miller's Crossing (1990).mkv", Satellite, Blaxploitation, 1990s, Popcorn, -, 1990s, false, wrong_tier, medium, "US Crime/Drama; no Blaxploitation signals"
"Deep Red (1975).mkv", Satellite, Giallo, 1970s, Satellite, Giallo, 1970s, true, -, high, "Director match: Argento"
```

### What it does NOT do

- Does not move files
- Does not modify `sorting_manifest.csv`
- Does not modify `SORTING_DATABASE.md`
- Does not modify any cache
- Does not call APIs (reads from existing caches only — no cost)

The discrepancy report is input for human review. The curator decides what to do with each flagged film: reclassify, pin via SORTING_DATABASE.md, or investigate the routing rules.

---

## Implementation

### Data flow

```
library_audit.csv (audit.py output)
  → for each film:
      → parse filename (lib/parser.py)
      → lookup in tmdb_cache.json + omdb_cache.json
      → run through classification stages (reuse classify.py logic)
      → compare result to current_tier/current_category from audit
  → output/reaudit_report.csv
```

### Reuse existing classification logic

The script should reuse the classification pipeline from `classify.py`, not reimplement it. The key methods:
- `FilmClassifier._check_explicit_lookup()` — Stage 2
- `FilmClassifier._check_reference_canon()` — Stage 3
- `SatelliteClassifier.classify()` — Stages 4–5
- `CoreDirectorDatabase.is_core_director()` — Stage 7
- `PopcornClassifier.classify()` — Stage 8

The script needs to instantiate these classifiers and run each film through the same stage sequence. This may require refactoring `classify.py` to expose the classification logic as importable functions rather than methods bound to the full pipeline's file-discovery loop.

### Handling missing API data

Many manually-placed films have no cache entries (never queried). The script should:
1. First pass: classify using existing cache data only (no API calls, $0 cost)
2. Flag `no_data` films separately — these need API enrichment before they can be reclassified
3. Optional second pass: `--enrich` flag triggers API queries for `no_data` films (costs API calls)

### Stages

**Stage 1: Build the script (read-only, cache-only)**
- Read `library_audit.csv`
- Parse each filename
- Look up in existing caches
- Run through classification stages
- Output discrepancy report
- Expected: immediate results for films with cache entries; `no_data` flags for the rest

**Stage 2: API enrichment for uncached films**
- Add `--enrich` flag
- For `no_data` films, query TMDb + OMDb and save to cache
- Re-run classification on newly enriched films
- Update discrepancy report
- Expected: most manually-placed films get reclassified; some remain unresolvable

**Stage 3: Human review workflow**
- Add `--review` flag that outputs a human-friendly markdown report grouped by category
- Show each category's discrepancies sorted by confidence
- Include suggested action (reclassify / pin / investigate)
- This is the curator's working document for the Stage 3 refinement pass

---

## Relationship to other issues

- **Issue #30 (tentpole ranking):** Blocked by this issue. Tentpole ranking (Stage 4) requires clean categories (Stage 3). The re-audit tool is the prerequisite.
- **Issue #29 (text signal enrichment):** Independent. Text signals improve classification quality but are not required for the re-audit — director match and country/genre/decade are sufficient for most discrepancies.
- **Issue #28 (classification model revision):** Complementary. The re-audit will surface cases where the routing rules themselves need revision, feeding into Issue #28's model changes.

---

## Cross-references

- `docs/theory/REFINEMENT_AND_EMERGENCE.md` §4a — The curatorial lifecycle that this tool enables (Stages 3–5)
- `docs/theory/SATELLITE_DEPTH.md` §5 — Prerequisite note: within-category vetting requires clean categories
- `docs/theory/REFINEMENT_AND_EMERGENCE.md` §4 Component 3 — Previously acknowledged the gap ("future `--audit-existing` mode")
- `docs/archive/SATELLITE_RESTRUCTURE_v03.md` Phase 5 — Earlier draft proposal for `reclassify.py` (never built)
- `CLAUDE.md` §3 Rule 7 — Measurement-Driven Development: consistency (breadth-first) pass across the full library
